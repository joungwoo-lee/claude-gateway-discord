#!/usr/bin/env python3
"""
ì„¸ì…˜ ê²€ìƒ‰ ë…ë¦½ ìŠ¤í¬ë¦½íŠ¸ (ìŠ¤í‚¬ìš©)
- hybrid_retriever / local_embeddings ì˜ì¡´ì„± ì—†ìŒ
- í™˜ê²½ë³€ìˆ˜ë§Œ ì‚¬ìš© (main.pyê°€ .envë¥¼ ë¡œë“œí•˜ë¯€ë¡œ ì´ë¯¸ ì„¤ì •ë¨)
- external: HTTP POST (urllib, stdlibë§Œ ì‚¬ìš©)
- local: SQLite + numpy + sentence-transformers ì§ì ‘ ì‚¬ìš©
"""

import json
import os
import sqlite3
import sys
import urllib.request
import urllib.error
from pathlib import Path

# â”€â”€ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ìŒ) â”€â”€

CLAUDE_GATEWAY_SESSION_MEMORY = os.getenv("CLAUDE_GATEWAY_SESSION_MEMORY", "none").lower().strip()
BASE_URL = os.getenv("RETRIEVER_BASE_URL", "http://localhost:9380")
API_KEY = os.getenv("RETRIEVER_API_KEY", "secret-key")
DATASET_ID = os.getenv("RAG_DATASET_IDS", "mymemory")
TOP_N = int(os.getenv("RETRIEVER_TOP_N", "8"))
SIMILARITY_THRESHOLD = float(os.getenv("RETRIEVER_SIMILARITY_THRESHOLD", "0.2"))
SESSIONS_DIR = Path.home() / ".claude" / "gateway-sessions"


# â”€â”€ external ê²€ìƒ‰: stdlib urllib â”€â”€


def search_external(query: str, top_k: int) -> list[dict]:
    payload = json.dumps({
        "question": query,
        "dataset_ids": [DATASET_ID],
        "top_n": top_k,
    }).encode()

    req = urllib.request.Request(
        f"{BASE_URL}/api/v1/retrieval",
        data=payload,
        headers={
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json",
        },
        method="POST",
    )

    try:
        with urllib.request.urlopen(req, timeout=30) as resp:
            data = json.loads(resp.read())
    except urllib.error.HTTPError as e:
        print(f"HTTP {e.code}: {e.read().decode()[:200]}", file=sys.stderr)
        return []
    except Exception as e:
        print(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}", file=sys.stderr)
        return []

    results = []
    for item in data.get("data", {}).get("chunks", []):
        results.append({
            "content": item.get("content", ""),
            "similarity": item.get("similarity", 0.0),
            "file_name": item.get("document_name", ""),
            "thread_id": item.get("document_id", "").replace("oldsessions_", ""),
        })
    return results


# â”€â”€ local ê²€ìƒ‰: SQLite + numpy + sentence-transformers â”€â”€


def search_local(query: str, top_k: int) -> list[dict]:
    import numpy as np

    db_path = SESSIONS_DIR / "embeddings.db"
    if not db_path.exists():
        print("ì„ë² ë”© DBê°€ ì—†ìŠµë‹ˆë‹¤. ì„¸ì…˜ì´ ì¸ë±ì‹±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", file=sys.stderr)
        return []

    # ëª¨ë¸ ë¡œë“œ
    from sentence_transformers import SentenceTransformer
    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    model = SentenceTransformer(model_name)

    # ì¿¼ë¦¬ ì„ë² ë”©
    query_emb = model.encode(query, normalize_embeddings=True)

    # DB ê²€ìƒ‰
    conn = sqlite3.connect(str(db_path))
    try:
        rows = conn.execute(
            "SELECT thread_id, file_name, chunk_idx, content, embedding FROM embeddings"
        ).fetchall()
    finally:
        conn.close()

    if not rows:
        return []

    results = []
    for thread_id, file_name, chunk_idx, content, emb_bytes in rows:
        emb = np.frombuffer(emb_bytes, dtype=np.float32)
        similarity = float(np.dot(query_emb, emb))
        if similarity >= SIMILARITY_THRESHOLD:
            results.append({
                "content": content,
                "similarity": similarity,
                "file_name": file_name,
                "thread_id": thread_id,
            })

    results.sort(key=lambda x: x["similarity"], reverse=True)
    return results[:top_k]


# â”€â”€ ì¶œë ¥ â”€â”€


def print_results(query: str, results: list[dict]):
    print(f"\nğŸ” ê²€ìƒ‰ì–´: {query}")
    print(f"ğŸ“Š ëª¨ë“œ: {CLAUDE_GATEWAY_SESSION_MEMORY}")
    print("=" * 60)

    if not results:
        print("\nê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n{len(results)}ê°œ ê²°ê³¼:\n")
    for i, r in enumerate(results, 1):
        print(f"[{i}] ìœ ì‚¬ë„: {r['similarity']:.3f} | íŒŒì¼: {r['file_name']}")
        if r.get("thread_id"):
            print(f"    ìŠ¤ë ˆë“œ: {r['thread_id']}")
        print(f"    ë‚´ìš©: {r['content'][:200]}...")
        print()


# â”€â”€ main â”€â”€


def main():
    if CLAUDE_GATEWAY_SESSION_MEMORY == "none":
        print("CLAUDE_GATEWAY_SESSION_MEMORY=none â€” ì„¸ì…˜ ê¸°ì–µì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        sys.exit(0)

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python search_sessions.py <ê²€ìƒ‰ì–´> [--top-k N]")
        sys.exit(1)

    query = sys.argv[1]
    top_k = TOP_N

    if "--top-k" in sys.argv:
        idx = sys.argv.index("--top-k")
        if idx + 1 < len(sys.argv):
            try:
                top_k = int(sys.argv[idx + 1])
            except ValueError:
                print("--top-k ê°’ì€ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.", file=sys.stderr)
                sys.exit(1)

    if CLAUDE_GATEWAY_SESSION_MEMORY == "external":
        if not DATASET_ID:
            print("RAG_DATASET_IDSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", file=sys.stderr)
            sys.exit(1)
        results = search_external(query, top_k)
    elif CLAUDE_GATEWAY_SESSION_MEMORY == "local":
        results = search_local(query, top_k)
    else:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” CLAUDE_GATEWAY_SESSION_MEMORY ê°’: {CLAUDE_GATEWAY_SESSION_MEMORY}")
        sys.exit(1)

    print_results(query, results)


if __name__ == "__main__":
    main()
